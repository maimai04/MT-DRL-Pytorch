{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code implementation exploration\n",
    "This Notebook has been created with the goal to explore the way the code implementation of stable-baselines and openai actually work, based on small \"dummy\"-cases.\n",
    "   \n",
    "   \n",
    "1. Environment\n",
    "2. Agent framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by: \n",
    "# https://costa.sh/blog-the-32-implementation-details-of-ppo.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from env import FinancialMarketEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of possible steps:  4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datadate</th>\n",
       "      <th>tic</th>\n",
       "      <th>adjcp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090102</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>12.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090102</td>\n",
       "      <td>AXP</td>\n",
       "      <td>19.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090102</td>\n",
       "      <td>BA</td>\n",
       "      <td>45.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090105</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>13.511429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090105</td>\n",
       "      <td>AXP</td>\n",
       "      <td>19.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090105</td>\n",
       "      <td>BA</td>\n",
       "      <td>46.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090106</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>13.288571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090106</td>\n",
       "      <td>AXP</td>\n",
       "      <td>21.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090106</td>\n",
       "      <td>BA</td>\n",
       "      <td>46.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090107</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>13.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090107</td>\n",
       "      <td>AXP</td>\n",
       "      <td>20.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090107</td>\n",
       "      <td>BA</td>\n",
       "      <td>44.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090108</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>13.242857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090108</td>\n",
       "      <td>AXP</td>\n",
       "      <td>20.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090108</td>\n",
       "      <td>BA</td>\n",
       "      <td>44.790000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   datadate   tic      adjcp\n",
       "0  20090102  AAPL  12.964286\n",
       "0  20090102   AXP  19.330000\n",
       "0  20090102    BA  45.250000\n",
       "1  20090105  AAPL  13.511429\n",
       "1  20090105   AXP  19.950000\n",
       "1  20090105    BA  46.170000\n",
       "2  20090106  AAPL  13.288571\n",
       "2  20090106   AXP  21.070000\n",
       "2  20090106    BA  46.310000\n",
       "3  20090107  AAPL  13.001429\n",
       "3  20090107   AXP  20.010000\n",
       "3  20090107    BA  44.760000\n",
       "4  20090108  AAPL  13.242857\n",
       "4  20090108   AXP  20.040000\n",
       "4  20090108    BA  44.790000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dummy data\n",
    "dumdat = pd.read_csv(\"data/preprocessed/done_data.csv\", index_col=0)\n",
    "dumdat = dumdat[[\"datadate\", \"tic\", \"adjcp\"]]\n",
    "dumdat.index = dumdat[\"datadate\"].factorize()[0]\n",
    "# only pick 3 stocks\n",
    "dumdat = dumdat.loc[dumdat[\"tic\"].isin([\"AAPL\", \"AXP\", \"BA\"])]\n",
    "# reduce data set to 5 days (4 possible steps)\n",
    "episode_length_steps = 5 \n",
    "dumdat = dumdat.loc[1-1:episode_length_steps-1]\n",
    "print(\"number of possible steps: \", len(dumdat.index.unique())-1)\n",
    "dumdat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10000.        ,    12.96428571,    19.33      ,    45.25      ,\n",
       "           0.        ,     0.        ,     0.        ])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dummy environment for FinancialMarketEnv: Dummy_FinancialMarketEnv\n",
    "# it is very similar to the actual environment used in the thesis, FinancialMarketEnv, \n",
    "# but there are less variables tracked and the action consists of simply appending \n",
    "# sampled actions to the state space, sice it is just for illustration\n",
    "\n",
    "class Dummy_FinancialMarketEnv(gym.Env):\n",
    "    def __init__(self, df, day=0, assets_dim=3, initial_cash_balance=10000):\n",
    "        self.df = df\n",
    "        self.day = day\n",
    "        self.data = self.df.loc[self.day, :] \n",
    "        self.assets_dim = assets_dim\n",
    "        self.initial_cash_balance = initial_cash_balance\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.assets_dim,))\n",
    "        # we observe 1 feature (adjcp) for each of the 3 stocks + 1 cash account = 30+1\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(self.assets_dim+1,))\n",
    "        self.actions = [0]*self.assets_dim\n",
    "        self.state = [self.initial_cash_balance] + \\\n",
    "                            self.data[\"adjcp\"].values.tolist() + self.actions\n",
    "        self.reward = 0\n",
    "        self.terminal_state = False\n",
    "        self.step_counter = 0\n",
    "\n",
    "    def step(self, action=None):\n",
    "        self.action = action      \n",
    "        #print(\"action: \",self.action not None)\n",
    "        self.terminal_state = self.day >= self.df.index.unique()[-1] # :bool\n",
    "        if self.terminal_state: \n",
    "            print(\"reached end of dataset at step\", self.step_counter)\n",
    "            return self.state, self.reward, self.terminal_state, {}\n",
    "        else: \n",
    "            self.step_counter+=1\n",
    "            self.day +=1\n",
    "            self.data = self.df.loc[self.day, :]\n",
    "            if isinstance(self.action,(list,pd.core.series.Series,np.ndarray)): \n",
    "                self.actions = self.action.tolist()  \n",
    "            self.state = [self.initial_cash_balance] + self.data[\"adjcp\"].values.tolist() + \\\n",
    "                             self.actions\n",
    "            self.state = np.asarray(self.state) # state must be array, also easier for computation\n",
    "            return self.state, self.reward, self.terminal_state, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.day = 0 \n",
    "        self.data = self.df.loc[self.day, :]\n",
    "        self.actions = [0]*self.assets_dim\n",
    "        self.state = [self.initial_cash_balance] + \\\n",
    "                            self.data[\"adjcp\"].values.tolist() + self.actions\n",
    "        self.state = np.asarray(self.state)\n",
    "        self.reward = 0\n",
    "        self.terminal_state = False\n",
    "        self.step_counter = 0\n",
    "        return self.state\n",
    "    def render(self, mode=\"human\", close=False):\n",
    "        return self.state\n",
    "\n",
    "# instantiate environment object\n",
    "env = Dummy_FinancialMarketEnv(df=dumdat)\n",
    "\n",
    "# when resetting the environment, it should return the current state\n",
    "# and by definition this current state after reset should be the starting state\n",
    "# (we have defined the starting state as cash balance 10'000 and then the first asset prices \n",
    "# of the provided data set and at the end, asset holdings at the beginning for each asset\n",
    "# must be 0, as we start out with cash only before the first trade)\n",
    "# state = [initial_cash_balance, price AAPL, price AXP, \n",
    "#          price BA, holdings AAPL, holdings AXP, holdings BA]\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Dummy_agent \n",
    "class Dummy_agent():\n",
    "    def __init__(self, env=env, state=None, reward=None, action_sampling=True):\n",
    "        self.env = env\n",
    "        self.state = state\n",
    "        self.reward = reward\n",
    "        self.action_sampling = action_sampling\n",
    "    def sample_action(self):\n",
    "        if self.action_sampling: \n",
    "            # if the env is passed (hence not none), sampke from action space in the environment\n",
    "            action = self.env.action_space.sample()\n",
    "        else:\n",
    "            # if the environment is None (no environment passed to the agent), take no action\n",
    "            # and just observe the new day sampled in the environment\n",
    "            action = None\n",
    "        return action\n",
    "\n",
    "# instantiate agent object\n",
    "agent = Dummy_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training algorithm\n",
    "def training_algorithm(instantiated_agent, instantiated_env, n_episodes=3):\n",
    "    for i in range(1, n_episodes+1):\n",
    "        all_obs = [env.reset()]\n",
    "        while True:\n",
    "            action = agent.sample_action()\n",
    "            obs, reward, done, info = env.step(action=action)\n",
    "            all_obs += [obs]\n",
    "            if done:\n",
    "                print(f\"all observations in episode {i}:\")\n",
    "                print(pd.DataFrame(all_obs, columns=[\"cash\", \"AAPL_price\", \"AXP_price\", \n",
    "                                                     \"BA_price\",\"AAPL_holdings\", \"AXP_holdings\", \n",
    "                                                     \"BA_holdings\"]))\n",
    "                print(\"true termination\\n\")\n",
    "                print()\n",
    "                break\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. How the termination and seeding works\n",
    "There are two ways an episode can be terminated:\n",
    "- **True termination** of an episode happens, when the condition of terminal_state is true (see example below, defined in the environment). \n",
    "This condition is coded within the environment. The termination condition can be the death of an agent (like falling out of the grid world), or reaching a certain goal (like the end of the labirinth).   \n",
    "In this thesis, the \"true termination condition\" is such that if the ending of the provided (train, validation, test) data set is reached, the episode naturally ends.   \n",
    "Note: in other use cases in financial trading it could also make sense to terminate the episode when a certain wealth level (=> goal) is reached (and then liquidate all stocks and migrate to an island and receive an extra reward etc.).    \n",
    "Since in asset / investment management, usually the goal is to stay invested over longer periods (e.g. years, until retirement, reaching financial independence, over multiple generations,...) and not to reach short-term gains (although this would be nice, it is not the main goal of classical investment management), hence a termination when the end of the data set is reached makes most sense.\n",
    "\n",
    "- **Time limit termination**: When the episode could go on indefinitely, we can set a limit to the maximum number of time steps within one episode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True episode termination - 3 episodes, no actions (agent only moves from one day to the other within the environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**:\n",
    "Below in the output, we see that for every episode, the same data in the same sequential order is sampled.   \n",
    "The first entry of a list (10000) is the initial cash balance, the next 3 entries are the asset prices of the 3 assets we look at, the final 3 empty entries (0) are number of asset holdings.    \n",
    "Currently, we don't take any action, we only sample a new day at each step. This is done to make it simpler to understand what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of dataset at step 4\n",
      "all observations in episode 1:\n",
      "      cash  AAPL_price  AXP_price  BA_price  AAPL_holdings  AXP_holdings  \\\n",
      "0  10000.0   12.964286      19.33     45.25            0.0           0.0   \n",
      "1  10000.0   13.511429      19.95     46.17            0.0           0.0   \n",
      "2  10000.0   13.288571      21.07     46.31            0.0           0.0   \n",
      "3  10000.0   13.001429      20.01     44.76            0.0           0.0   \n",
      "4  10000.0   13.242857      20.04     44.79            0.0           0.0   \n",
      "5  10000.0   13.242857      20.04     44.79            0.0           0.0   \n",
      "\n",
      "   BA_holdings  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n",
      "5          0.0  \n",
      "true termination\n",
      "\n",
      "\n",
      "reached end of dataset at step 4\n",
      "all observations in episode 2:\n",
      "      cash  AAPL_price  AXP_price  BA_price  AAPL_holdings  AXP_holdings  \\\n",
      "0  10000.0   12.964286      19.33     45.25            0.0           0.0   \n",
      "1  10000.0   13.511429      19.95     46.17            0.0           0.0   \n",
      "2  10000.0   13.288571      21.07     46.31            0.0           0.0   \n",
      "3  10000.0   13.001429      20.01     44.76            0.0           0.0   \n",
      "4  10000.0   13.242857      20.04     44.79            0.0           0.0   \n",
      "5  10000.0   13.242857      20.04     44.79            0.0           0.0   \n",
      "\n",
      "   BA_holdings  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n",
      "5          0.0  \n",
      "true termination\n",
      "\n",
      "\n",
      "reached end of dataset at step 4\n",
      "all observations in episode 3:\n",
      "      cash  AAPL_price  AXP_price  BA_price  AAPL_holdings  AXP_holdings  \\\n",
      "0  10000.0   12.964286      19.33     45.25            0.0           0.0   \n",
      "1  10000.0   13.511429      19.95     46.17            0.0           0.0   \n",
      "2  10000.0   13.288571      21.07     46.31            0.0           0.0   \n",
      "3  10000.0   13.001429      20.01     44.76            0.0           0.0   \n",
      "4  10000.0   13.242857      20.04     44.79            0.0           0.0   \n",
      "5  10000.0   13.242857      20.04     44.79            0.0           0.0   \n",
      "\n",
      "   BA_holdings  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n",
      "5          0.0  \n",
      "true termination\n",
      "\n",
      "\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "# get data and reduce data set to 5 days (4 possible steps)\n",
    "episode_length_steps = 5 \n",
    "dumdat = dumdat.loc[1-1:episode_length_steps-1]\n",
    "\n",
    "# instantiate environment object\n",
    "env = Dummy_FinancialMarketEnv(df=dumdat)\n",
    "env.reset()\n",
    "# instantiate agent object (sample_action = Fals we wpn't take any action for now, just\n",
    "# observe the state ofthe next day)\n",
    "agent = Dummy_agent(env=env, state=None, reward=None, action_sampling=False)\n",
    "\n",
    "# number of episodes chosen in total: 3; chosen arbitrarily, just for illustration\n",
    "n_episodes = 3 \n",
    "# run the training algorithm\n",
    "training_algorithm(instantiated_agent=agent, instantiated_env=env, n_episodes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True episode termination - 3 episodes, sampled actions randomly from defined action space\n",
    "now, we are going to have a look at what happens if we sample actions from the environment.  \n",
    "Recall that we defined the action space in the environment above, and from this action space we are going to sample. Here, we don't set any random seed.  \n",
    "\n",
    "The actions here are very simple and only for illustration: the actions vector is simply appended to the state vector, so instead of [0,0,0] at the end of each state vector, we are going to fill these numbers with the corresponding actions sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.98027253, -0.26714474,  0.53676194], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is how the agent we defined above samples the action space\n",
    "# every time this is run, a new sample is generated \n",
    "env.action_space.sample()\n",
    "# (non-deterministic), since no seeding here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**:\n",
    "Below in the output, we see that for every episode, again, the same data in the same sequential order is sampled.   \n",
    "  \n",
    "The actions were sampled without fixing the random seed, hence they are different in every episode 8=asset holdings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of dataset at step 4\n",
      "all observations in episode 1:\n",
      "      cash  AAPL_price  AXP_price  BA_price  AAPL_holdings  AXP_holdings  \\\n",
      "0  10000.0   12.964286      19.33     45.25       0.000000      0.000000   \n",
      "1  10000.0   13.511429      19.95     46.17      -0.187715     -0.994984   \n",
      "2  10000.0   13.288571      21.07     46.31       0.206030     -0.341867   \n",
      "3  10000.0   13.001429      20.01     44.76      -0.398915      0.419919   \n",
      "4  10000.0   13.242857      20.04     44.79      -0.914911      0.826951   \n",
      "5  10000.0   13.242857      20.04     44.79      -0.914911      0.826951   \n",
      "\n",
      "   BA_holdings  \n",
      "0     0.000000  \n",
      "1     0.524657  \n",
      "2     0.260012  \n",
      "3    -0.299572  \n",
      "4     0.146937  \n",
      "5     0.146937  \n",
      "true termination\n",
      "\n",
      "\n",
      "reached end of dataset at step 4\n",
      "all observations in episode 2:\n",
      "      cash  AAPL_price  AXP_price  BA_price  AAPL_holdings  AXP_holdings  \\\n",
      "0  10000.0   12.964286      19.33     45.25       0.000000      0.000000   \n",
      "1  10000.0   13.511429      19.95     46.17      -0.836646      0.901422   \n",
      "2  10000.0   13.288571      21.07     46.31       0.648396     -0.492867   \n",
      "3  10000.0   13.001429      20.01     44.76      -0.679916     -0.081751   \n",
      "4  10000.0   13.242857      20.04     44.79       0.415539     -0.522546   \n",
      "5  10000.0   13.242857      20.04     44.79       0.415539     -0.522546   \n",
      "\n",
      "   BA_holdings  \n",
      "0     0.000000  \n",
      "1    -0.135437  \n",
      "2     0.633613  \n",
      "3    -0.789792  \n",
      "4     0.204209  \n",
      "5     0.204209  \n",
      "true termination\n",
      "\n",
      "\n",
      "reached end of dataset at step 4\n",
      "all observations in episode 3:\n",
      "      cash  AAPL_price  AXP_price  BA_price  AAPL_holdings  AXP_holdings  \\\n",
      "0  10000.0   12.964286      19.33     45.25       0.000000      0.000000   \n",
      "1  10000.0   13.511429      19.95     46.17      -0.991983      0.486981   \n",
      "2  10000.0   13.288571      21.07     46.31      -0.169333     -0.951073   \n",
      "3  10000.0   13.001429      20.01     44.76      -0.743700     -0.300007   \n",
      "4  10000.0   13.242857      20.04     44.79       0.128960      0.108535   \n",
      "5  10000.0   13.242857      20.04     44.79       0.128960      0.108535   \n",
      "\n",
      "   BA_holdings  \n",
      "0     0.000000  \n",
      "1    -0.980491  \n",
      "2     0.785538  \n",
      "3    -0.840354  \n",
      "4    -0.657783  \n",
      "5    -0.657783  \n",
      "true termination\n",
      "\n",
      "\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "# get data and reduce data set to 5 days (4 possible steps)\n",
    "episode_length_steps = 5 \n",
    "dumdat = dumdat.loc[1-1:episode_length_steps-1]\n",
    "# instantiate environment object\n",
    "env = Dummy_FinancialMarketEnv(df=dumdat)\n",
    "env.reset()\n",
    "# instantiate agent object (sample_action = True; this time, we will sample actions from the \n",
    "# pre-defined action space)\n",
    "agent = Dummy_agent(env=env, state=None, reward=None, action_sampling=True)\n",
    "\n",
    "# number of episodes chosen in total: 3; chosen arbitrarily, just for illustration\n",
    "n_episodes = 3 \n",
    "# run the training algorithm\n",
    "training_algorithm(instantiated_agent=agent, instantiated_env=env, n_episodes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**: \n",
    "Now we are going to use seeding in order to check, how it works.  \n",
    "We want to sample actions but we want this to be reproducible by using the same seed.  \n",
    "  \n",
    "env.seed(random_seed) is a function that simply returns the seed.    \n",
    "In order to seed the action space, the function env.action_space.seed(random_seed) needs to be called.  \n",
    "This returns a seeded numpy rng (random numbers generator), which then samples actions randomly but in the same order every time we start anew.  \n",
    "This is demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this function only returns the seed (or seeds list, in case of multiple envs)\n",
    "env.seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02584589 -0.76794004  0.3478417 ]\n",
      "[ 0.41330826 -0.38325065  0.8453528 ]\n",
      "[-0.00483404  0.18476054  0.6489266 ]\n",
      "[-0.7800391  -0.5151238   0.47571707]\n",
      " \n",
      "[-0.02584589 -0.76794004  0.3478417 ]\n",
      "[ 0.41330826 -0.38325065  0.8453528 ]\n",
      "[-0.00483404  0.18476054  0.6489266 ]\n",
      "[-0.7800391  -0.5151238   0.47571707]\n"
     ]
    }
   ],
   "source": [
    "# every time we run this code, the action space samples are different \n",
    "# from each other but occur in the same order\n",
    "env.action_space.seed(11)\n",
    "print(env.action_space.sample())\n",
    "print(env.action_space.sample())\n",
    "print(env.action_space.sample())\n",
    "print(env.action_space.sample())\n",
    "print(\" \")\n",
    "env.action_space.seed(11)\n",
    "print(env.action_space.sample())\n",
    "print(env.action_space.sample())\n",
    "print(env.action_space.sample())\n",
    "print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://harald.co/2019/07/30/reproducibility-issues-using-openai-gym/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what happens, if we create a vecorized environment (wrap the vector class around it)?\n",
    "This is something I have to do in my work as well because the PPO and A2C agent need it (see also paper described in thesis). They do this to speed up processing /learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv at 0x23119983f08>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecenv = DummyVecEnv([lambda: Dummy_FinancialMarketEnv(df=dumdat)])\n",
    "vecenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dummy_FinancialMarketEnv instance>\n",
      "<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000023119983F08>\n",
      "\n",
      "[<__main__.Dummy_FinancialMarketEnv object at 0x0000023119983908>]\n",
      "<Dummy_FinancialMarketEnv instance>\n",
      "\n",
      "Box(-1.0, 1.0, (3,), float32)\n",
      "Box(-1.0, 1.0, (3,), float32)\n",
      "\n",
      "[10000.            12.96428571    19.33          45.25\n",
      "     0.             0.             0.        ]\n",
      "[10000.            12.96428571    19.33          45.25\n",
      "     0.             0.             0.        ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# differences between vectorized env and normal env from before?\n",
    "print(env)\n",
    "print(vecenv)\n",
    "print(\"\")\n",
    "# this is a list of environments, but since we have only passed one, it s length 1\n",
    "print(vecenv.envs) \n",
    "print(vecenv.envs[0]) # this is the only environment we have passed\n",
    "print(\"\")\n",
    "print(env.action_space)\n",
    "print(vecenv.action_space)\n",
    "print(\"\")\n",
    "print(env.reset()) # returns first state\n",
    "#print(vecenv.reset()) # does not work, returns error\n",
    "print(vecenv.envs[0].reset())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02584589, -0.76794004,  0.3478417 ], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vecenv.action_space.seed(11)\n",
    "vecenv.action_space.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of dataset at step 4\n",
      "all observations in episode 1:\n",
      "      cash  AAPL_price  AXP_price  BA_price  AAPL_holdings  AXP_holdings  \\\n",
      "0  10000.0   12.964286      19.33     45.25       0.000000      0.000000   \n",
      "1  10000.0   13.511429      19.95     46.17      -0.967771      0.839267   \n",
      "2  10000.0   13.288571      21.07     46.31       0.390801      0.289887   \n",
      "3  10000.0   13.001429      20.01     44.76      -0.685475      0.904185   \n",
      "4  10000.0   13.242857      20.04     44.79      -0.502355      0.542519   \n",
      "5  10000.0   13.242857      20.04     44.79      -0.502355      0.542519   \n",
      "\n",
      "   BA_holdings  \n",
      "0     0.000000  \n",
      "1     0.411189  \n",
      "2    -0.259051  \n",
      "3    -0.001251  \n",
      "4     0.905264  \n",
      "5     0.905264  \n",
      "true termination\n",
      "\n",
      "\n",
      "reached end of dataset at step 4\n",
      "all observations in episode 2:\n",
      "      cash  AAPL_price  AXP_price  BA_price  AAPL_holdings  AXP_holdings  \\\n",
      "0  10000.0   12.964286      19.33     45.25       0.000000      0.000000   \n",
      "1  10000.0   13.511429      19.95     46.17       0.006335     -0.836307   \n",
      "2  10000.0   13.288571      21.07     46.31      -0.828488     -0.078340   \n",
      "3  10000.0   13.001429      20.01     44.76      -0.524096      0.796884   \n",
      "4  10000.0   13.242857      20.04     44.79       0.905265      0.586366   \n",
      "5  10000.0   13.242857      20.04     44.79       0.905265      0.586366   \n",
      "\n",
      "   BA_holdings  \n",
      "0     0.000000  \n",
      "1     0.150430  \n",
      "2    -0.590431  \n",
      "3     0.656676  \n",
      "4    -0.205007  \n",
      "5    -0.205007  \n",
      "true termination\n",
      "\n",
      "\n",
      "reached end of dataset at step 4\n",
      "all observations in episode 3:\n",
      "      cash  AAPL_price  AXP_price  BA_price  AAPL_holdings  AXP_holdings  \\\n",
      "0  10000.0   12.964286      19.33     45.25       0.000000      0.000000   \n",
      "1  10000.0   13.511429      19.95     46.17      -0.824689     -0.447846   \n",
      "2  10000.0   13.288571      21.07     46.31      -0.071338      0.033739   \n",
      "3  10000.0   13.001429      20.01     44.76      -0.082523      0.219727   \n",
      "4  10000.0   13.242857      20.04     44.79       0.003025     -0.215451   \n",
      "5  10000.0   13.242857      20.04     44.79       0.003025     -0.215451   \n",
      "\n",
      "   BA_holdings  \n",
      "0     0.000000  \n",
      "1    -0.963799  \n",
      "2     0.851139  \n",
      "3    -0.450612  \n",
      "4     0.099337  \n",
      "5     0.099337  \n",
      "true termination\n",
      "\n",
      "\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "# get data and reduce data set to 5 days (4 possible steps)\n",
    "episode_length_steps = 5 \n",
    "dumdat = dumdat.loc[1-1:episode_length_steps-1]\n",
    "# instantiate environment object\n",
    "env = Dummy_FinancialMarketEnv(df=dumdat)\n",
    "env.reset()\n",
    "vecenv = DummyVecEnv([lambda: env])\n",
    "# instantiate agent object (sample_action = True; this time, we will sample actions from the \n",
    "# pre-defined action space)\n",
    "agent = Dummy_agent(env=env, state=None, reward=None, action_sampling=True)\n",
    "\n",
    "# number of episodes chosen in total: 3; chosen arbitrarily, just for illustration\n",
    "n_episodes = 3 \n",
    "# run the training algorithm\n",
    "training_algorithm(instantiated_agent=agent, instantiated_env=vecenv, n_episodes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10000.        ,    12.96428571,    19.33      ,    45.25      ,\n",
       "           0.        ,     0.        ,     0.        ])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}